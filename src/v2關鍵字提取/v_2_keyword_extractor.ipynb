{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##接收日記內容並返回3-5個關鍵字"
      ],
      "metadata": {
        "id": "wmHv2Aphp4L2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# keyword_extractor.py (最終淨化版：只包含函式和必要的導入)\n",
        "\n",
        "import json\n",
        "import jieba.analyse\n",
        "import os # <-- 新增：導入 os 模組\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# 🌟 停用詞載入區塊 (正式加入) 🌟\n",
        "# ----------------------------------------------------\n",
        "\n",
        "# 設置絕對路徑：請確認這個路徑是您檔案在 Google Drive 上的確切位置\n",
        "PROJECT_ROOT = '/content/drive/MyDrive/projects/LINE BOT'\n",
        "STOPWORDS_FILE = os.path.join(PROJECT_ROOT, 'v2_stopwords_new.txt') # <-- 使用您確認正確的檔案名稱\n",
        "\n",
        "if os.path.exists(STOPWORDS_FILE):\n",
        "    try:\n",
        "        # 這是唯一需要的函式：設置 Jieba 的停用詞檔案\n",
        "        jieba.analyse.set_stop_words(STOPWORDS_FILE)\n",
        "        # print(f\"✅ Jieba 已成功載入停用詞表: {STOPWORDS_FILE}\") # 可保留用於啟動時確認\n",
        "\n",
        "    except Exception as e:\n",
        "        # 這裡會捕捉到之前遇到的 'function' object has no attribute 'stop_words' 錯誤\n",
        "        # 但由於 set_stop_words 已經成功，我們不需要擔心\n",
        "        print(f\"⚠️ 載入停用詞時發生例外，但可能已成功應用: {e}\")\n",
        "# ----------------------------------------------------\n",
        "\n",
        "\n",
        "def extract_keywords_tfidf(text: str, topK: int = 5) -> str:\n",
        "    \"\"\"\n",
        "    使用 Jieba 內建的 TF-IDF 算法提取中文關鍵詞。\n",
        "    \"\"\"\n",
        "    if not text or len(text) < 5:\n",
        "        return json.dumps([])\n",
        "\n",
        "    try:\n",
        "        # 核心變動：呼叫 jieba.analyse.extract_tags\n",
        "        keywords_list = jieba.analyse.extract_tags(\n",
        "            sentence=text,\n",
        "            topK=topK,\n",
        "            withWeight=False,\n",
        "            allowPOS=('n', 'v', 'a')\n",
        "        )\n",
        "\n",
        "        if not keywords_list:\n",
        "             return json.dumps([])\n",
        "\n",
        "        return json.dumps(keywords_list, ensure_ascii=False)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Jieba TF-IDF 提取錯誤: {e}\")\n",
        "        return json.dumps([])\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # 執行單元測試\n",
        "    test_diary = \"今天工作上壓力很大，老闆突然叫我重做昨天晚上才交的簡報。雖然心情不太好，但晚餐吃了媽媽煮的紅燒肉，感覺好多了。希望明天可以順利完成專案。\"\n",
        "\n",
        "    keywords_json = extract_keywords_tfidf(test_diary, topK=4)\n",
        "\n",
        "    print(f\"測試日記：{test_diary}\")\n",
        "    print(f\"提取結果：{keywords_json}\")\n",
        "\n",
        "    if keywords_json and keywords_json != '[]':\n",
        "        print(f\"解碼列表：{json.loads(keywords_json)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrMC3rAg401q",
        "outputId": "3c12129e-4eee-4282-9dc4-e03cec3c54fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "測試日記：今天工作上壓力很大，老闆突然叫我重做昨天晚上才交的簡報。雖然心情不太好，但晚餐吃了媽媽煮的紅燒肉，感覺好多了。希望明天可以順利完成專案。\n",
            "提取結果：[\"壓力\", \"簡報\", \"媽媽\", \"紅燒肉\"]\n",
            "解碼列表：['壓力', '簡報', '媽媽', '紅燒肉']\n"
          ]
        }
      ]
    }
  ]
}