# -*- coding: utf-8 -*-
"""v.2_keyword_extractor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1n8xakpCfrP_hVEBvM4i4pbti4Vc1eQbC

##æ¥æ”¶æ—¥è¨˜å…§å®¹ä¸¦è¿”å›3-5å€‹é—œéµå­—
"""

# keyword_extractor.py (æœ€çµ‚æ·¨åŒ–ç‰ˆï¼šåªåŒ…å«å‡½å¼å’Œå¿…è¦çš„å°å…¥)

import json
import jieba.analyse
import os # <-- æ–°å¢ï¼šå°å…¥ os æ¨¡çµ„

# ----------------------------------------------------
# ğŸŒŸ åœç”¨è©è¼‰å…¥å€å¡Š (æ­£å¼åŠ å…¥) ğŸŒŸ
# ----------------------------------------------------

# è¨­ç½®çµ•å°è·¯å¾‘ï¼šè«‹ç¢ºèªé€™å€‹è·¯å¾‘æ˜¯æ‚¨æª”æ¡ˆåœ¨ Google Drive ä¸Šçš„ç¢ºåˆ‡ä½ç½®
PROJECT_ROOT = '/content/drive/MyDrive/projects/LINE BOT'
STOPWORDS_FILE = os.path.join(PROJECT_ROOT, 'v2_stopwords_new.txt') # <-- ä½¿ç”¨æ‚¨ç¢ºèªæ­£ç¢ºçš„æª”æ¡ˆåç¨±

if os.path.exists(STOPWORDS_FILE):
    try:
        # é€™æ˜¯å”¯ä¸€éœ€è¦çš„å‡½å¼ï¼šè¨­ç½® Jieba çš„åœç”¨è©æª”æ¡ˆ
        jieba.analyse.set_stop_words(STOPWORDS_FILE)
        # print(f"âœ… Jieba å·²æˆåŠŸè¼‰å…¥åœç”¨è©è¡¨: {STOPWORDS_FILE}") # å¯ä¿ç•™ç”¨æ–¼å•Ÿå‹•æ™‚ç¢ºèª

    except Exception as e:
        # é€™è£¡æœƒæ•æ‰åˆ°ä¹‹å‰é‡åˆ°çš„ 'function' object has no attribute 'stop_words' éŒ¯èª¤
        # ä½†ç”±æ–¼ set_stop_words å·²ç¶“æˆåŠŸï¼Œæˆ‘å€‘ä¸éœ€è¦æ“”å¿ƒ
        print(f"âš ï¸ è¼‰å…¥åœç”¨è©æ™‚ç™¼ç”Ÿä¾‹å¤–ï¼Œä½†å¯èƒ½å·²æˆåŠŸæ‡‰ç”¨: {e}")
# ----------------------------------------------------


def extract_keywords_tfidf(text: str, topK: int = 5) -> str:
    """
    ä½¿ç”¨ Jieba å…§å»ºçš„ TF-IDF ç®—æ³•æå–ä¸­æ–‡é—œéµè©ã€‚
    """
    if not text or len(text) < 5:
        return json.dumps([])

    try:
        # æ ¸å¿ƒè®Šå‹•ï¼šå‘¼å« jieba.analyse.extract_tags
        keywords_list = jieba.analyse.extract_tags(
            sentence=text,
            topK=topK,
            withWeight=False,
            allowPOS=('n', 'v', 'a')
        )

        if not keywords_list:
             return json.dumps([])

        return json.dumps(keywords_list, ensure_ascii=False)

    except Exception as e:
        print(f"Jieba TF-IDF æå–éŒ¯èª¤: {e}")
        return json.dumps([])

if __name__ == '__main__':
    # åŸ·è¡Œå–®å…ƒæ¸¬è©¦
    test_diary = "ä»Šå¤©å·¥ä½œä¸Šå£“åŠ›å¾ˆå¤§ï¼Œè€é—†çªç„¶å«æˆ‘é‡åšæ˜¨å¤©æ™šä¸Šæ‰äº¤çš„ç°¡å ±ã€‚é›–ç„¶å¿ƒæƒ…ä¸å¤ªå¥½ï¼Œä½†æ™šé¤åƒäº†åª½åª½ç…®çš„ç´…ç‡’è‚‰ï¼Œæ„Ÿè¦ºå¥½å¤šäº†ã€‚å¸Œæœ›æ˜å¤©å¯ä»¥é †åˆ©å®Œæˆå°ˆæ¡ˆã€‚"

    keywords_json = extract_keywords_tfidf(test_diary, topK=4)

    print(f"æ¸¬è©¦æ—¥è¨˜ï¼š{test_diary}")
    print(f"æå–çµæœï¼š{keywords_json}")

    if keywords_json and keywords_json != '[]':
        print(f"è§£ç¢¼åˆ—è¡¨ï¼š{json.loads(keywords_json)}")